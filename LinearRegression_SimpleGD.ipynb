{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d606186-c4c6-4815-b9a5-79d2b773c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @forward pass\n",
    "# loss fn\n",
    "# gradients\n",
    "# updating gradients\n",
    "# y^ = X.W + b\n",
    "# error = y^- y\n",
    "# J = (1/2m) * Σ(error**2)\n",
    "# dw = 1/m * Σ(X.T * error)\n",
    "# db = 1/m * Σ(error)\n",
    "# w = w - alpha * dw\n",
    "# b = b - alpha * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc7190f-2f17-4b41-abed-344724656795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegressionGD:\n",
    "    #init, fit, predict\n",
    "    def __init__(self, alpha = 0.1, iterations = 1000):\n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_instances, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        for i in range(self.iterations):\n",
    "            #forward pass\n",
    "            pred_y = np.dot(X, self.weights) + self.bias\n",
    "            #error\n",
    "            error = pred_y - y\n",
    "            #loss\n",
    "            loss = np.mean(error**2)\n",
    "            if i%1000 == 0:\n",
    "                print(f\"loss at {i} iteration is {loss}\")\n",
    "            #gradients\n",
    "            dw = np.dot(X.T, error) / n_instances\n",
    "            db = np.sum(error) /n_instances\n",
    "            #gradient update\n",
    "            self.weights = self.weights - self.alpha * dw\n",
    "            self.bias = self.bias - self.alpha * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f4f1d50-9ed7-4034-946f-5849d7286a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionSGD:\n",
    "    #init, fit, predict\n",
    "    def __init__(self, alpha = 0.1, iterations = 1000, batch_size = 64):\n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_instances, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        #Mini batch SGD\n",
    "        for _ in range(self.iterations):\n",
    "            #shuffle the data\n",
    "            indices = np.random.permutation(n_instances) #n_instances = 100 it returns 0 to 99 in a shuffled indices = [4,98,0,....,1,2]\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "\n",
    "            for i in range(0, n_instances, self.batch_size): #i =0, 0+64, 128, so on\n",
    "                X_batch = X_shuffled[i: i +self.batch_size]\n",
    "                y_batch = y_shuffled[i: i +self.batch_size]\n",
    "                #forward pass\n",
    "                pred_y = np.dot(X_batch, self.weights) + self.bias\n",
    "                error = pred_y - y_batch\n",
    "                #gradients # dw = 1/m * Σ(X.T * error)\n",
    "                # db = 1/m * Σ(error)\n",
    "                dw = np.dot(X_batch.T, error) / len(X_batch)\n",
    "                db = np.sum(error) / len(X_batch)\n",
    "                #gradient update\n",
    "                self.weights = self.weights - self.alpha * dw\n",
    "                self.bias = self.bias - self.alpha * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf7cbff-81b9-44d2-b7ff-a11c99e1da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_diabetes(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "X = df.drop(columns=[\"target\"]).values\n",
    "y = df[\"target\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb56a51-d3c6-4521-af16-b1ba693db744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at 0 iteration is 29711.32294617564\n",
      "loss at 1000 iteration is 4008.446876737857\n",
      "loss at 2000 iteration is 3443.577918490817\n",
      "loss at 3000 iteration is 3214.7373024153208\n",
      "loss at 4000 iteration is 3094.0715404302573\n",
      "loss at 5000 iteration is 3022.883922921272\n",
      "loss at 6000 iteration is 2979.024610480903\n",
      "loss at 7000 iteration is 2951.4107485581694\n",
      "loss at 8000 iteration is 2933.7448439816944\n",
      "loss at 9000 iteration is 2922.2725655888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([142.6302984 , 177.20486571, 141.80764598, 289.4203295 ,\n",
       "       124.91078374,  98.61468745, 252.10688087, 191.55248404,\n",
       "        88.41342437, 115.47377347,  96.36088178, 154.81313019,\n",
       "        65.94589262, 209.02420815, 105.54079599, 135.52234042,\n",
       "       223.22697556, 246.25827849, 193.69242364, 213.23282734,\n",
       "       200.6117166 ,  89.42938074,  76.44105239, 188.46120071,\n",
       "       153.95262118, 164.45986524, 187.73749881, 176.24680176,\n",
       "        51.95783925, 117.07065057, 179.72530895,  94.349441  ,\n",
       "       133.32434145, 181.91734578, 173.0727751 , 189.56252606,\n",
       "       126.94837779, 123.68325753, 152.72348896,  61.44699847,\n",
       "        81.66610406, 112.12475683, 158.76526185, 153.75551598,\n",
       "       173.69280551,  66.10559619,  82.62400755, 106.033354  ,\n",
       "        61.8114628 , 154.91951309, 152.68083722,  65.89075468,\n",
       "       116.87810138, 109.79443004, 169.6528556 , 154.73169551,\n",
       "        98.78389552, 203.01842262, 115.27793949,  69.01949261,\n",
       "       183.19516116, 195.93706305, 141.38339331, 111.70735585,\n",
       "       126.47397047, 197.19154438, 168.37528539, 160.18052212,\n",
       "       112.81378423, 140.21770358, 178.20377919, 195.67366136,\n",
       "       238.95719488, 141.9965111 ,  83.05477384, 151.13522909,\n",
       "       195.80217362, 199.76065029, 159.96721858, 194.35186288,\n",
       "       115.94168335, 130.86619381,  55.25253555,  60.77605695,\n",
       "       113.07622935,  88.63387136,  78.41151395,  64.16396037,\n",
       "       158.13385766])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegressionGD(alpha = 0.1, iterations = 10000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e05286-05ce-4565-86ac-52d5e39900b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([140.02391869, 181.06406872, 139.63486175, 294.09671694,\n",
       "       120.53435429,  92.83219428, 256.81544439, 186.93637495,\n",
       "        82.96436759, 110.30232398,  94.48208409, 162.29058985,\n",
       "        63.35622276, 204.83853236,  97.98450406, 131.70729427,\n",
       "       221.39269973, 246.24981071, 195.83395185, 214.15194185,\n",
       "       207.22578566,  88.12797285,  71.43656602, 187.89553712,\n",
       "       156.05118857, 161.58665137, 189.40833807, 176.38028163,\n",
       "        49.22225833, 109.77676548, 180.06205054,  90.90254587,\n",
       "       130.75215218, 180.05427188, 172.59018719, 190.94836095,\n",
       "       121.58175075, 117.01777586, 144.54540224,  60.27961179,\n",
       "        73.86005244, 107.11248367, 161.45065145, 148.35161138,\n",
       "       175.15494031,  64.96761919,  77.95627919, 106.35979545,\n",
       "        57.88736047, 160.96960268, 156.88986522,  64.97264762,\n",
       "       113.16926382, 107.44938423, 169.2680961 , 159.94304841,\n",
       "        93.68412279, 207.49782277, 117.59819114,  68.00173573,\n",
       "       184.30934252, 202.42387291, 141.15418331, 104.35881501,\n",
       "       125.30536209, 203.6640478 , 166.36396748, 161.26352942,\n",
       "       118.27948772, 140.03038765, 179.94352734, 194.25384867,\n",
       "       235.00565925, 142.17126306,  81.9586178 , 150.01430814,\n",
       "       192.75824329, 205.81878915, 157.05611147, 198.77309835,\n",
       "       113.82312647, 137.21261858,  53.16370809,  55.18849267,\n",
       "       110.79850668,  84.40622392,  80.22686173,  61.12373381,\n",
       "       163.72371703])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegressionSGD(alpha = 0.1, iterations = 10000, batch_size = 64)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "071041e6-11b4-4586-b239-2bdf520ca044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139.5475584 , 179.51720835, 134.03875572, 291.41702925,\n",
       "       123.78965872,  92.1723465 , 258.23238899, 181.33732057,\n",
       "        90.22411311, 108.63375858,  94.13865744, 168.43486358,\n",
       "        53.5047888 , 206.63081659, 100.12925869, 130.66657085,\n",
       "       219.53071499, 250.7803234 , 196.3688346 , 218.57511815,\n",
       "       207.35050182,  88.48340941,  70.43285917, 188.95914235,\n",
       "       154.8868162 , 159.36170122, 188.31263363, 180.39094033,\n",
       "        47.99046561, 108.97453871, 174.77897633,  86.36406656,\n",
       "       132.95761215, 184.53819483, 173.83220911, 190.35858492,\n",
       "       124.4156176 , 119.65110656, 147.95168682,  59.05405241,\n",
       "        71.62331856, 107.68284704, 165.45365458, 155.00975931,\n",
       "       171.04799096,  61.45761356,  71.66672581, 114.96732206,\n",
       "        51.57975523, 167.57599528, 152.52291955,  62.95568515,\n",
       "       103.49741722, 109.20751489, 175.64118426, 154.60296242,\n",
       "        94.41704366, 210.74209145, 120.2566205 ,  77.61585399,\n",
       "       187.93203995, 206.49337474, 140.63167076, 105.59678023,\n",
       "       130.70432536, 202.18534537, 171.13039501, 164.91423047,\n",
       "       124.72472569, 144.81030894, 181.99635452, 199.41369642,\n",
       "       234.21436188, 145.95665512,  79.86703276, 157.36941275,\n",
       "       192.74412541, 208.89814032, 158.58722555, 206.02195855,\n",
       "       107.47971675, 140.93598906,  54.82129332,  55.92573195,\n",
       "       115.01180018,  78.95584188,  81.56087285,  54.37997256,\n",
       "       166.2543518 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b828f3-a3ea-423b-84c5-8c508792ffb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
